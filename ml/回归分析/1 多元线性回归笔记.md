# 1 多元线性回归

## 1.1 基本形式

线性模型试图学得一个通过属性的线性组合来预测的函数，基本形式如下：
$$f(x)=w_1x_1+w_2x_2+...+w_dx_d+b \tag{1.1}$$
向量形式如下:
$$f(x)=w^{T}x+b \tag{1.2}$$

## 1.2 $w$与$b$的确定

### 1.2.1 一元

一般采用最小二乘法确定模型参数,一元情形推导如下：

$$
\begin{align}
 (w^*,b^*) &= \mathop{\arg\min}\limits_{(w,b)}\sum_{i=1}^{m}{(f(x_i)-yi)^2}\nonumber\\&=\mathop{\arg\min}\limits_{(w,b)}\sum_{i=1}^{m}{(y_i-wx_i-b)^2} \tag{1.3}
\end{align}
$$

我们令$E_{(w,b)}=\mathop{\arg\min}\limits_{(w,b)}\sum_{i=1}^{m}{(y_i-wx_i-b)^2}$，等式两边同时对$w$和$b$求导有：

$$
\begin{align}
  \frac{\partial E_{(w,b)}}{\partial b} &=2\Big(mb- \sum_{i=1}^m(y_i-wx_i)\Big) \tag{1.4}
\end{align}
$$

$$
\begin{align}
\frac{\partial E_{(w,b)}}{\partial w} &= \sum_{i=1}^{m}2(y_i-wx_i-b)(-x_i) \nonumber \\ &= 2 \Big (w\sum_{i_1}^mx^2-\sum_{i=1}^m(y_i-b)x_i\Big ) \tag{1.5}
\end{align}
$$

然后令式(1.4)和(1.5)为零得到：

$$
\begin{align}
  b&=\frac{1}{m}\sum_{i=1}^my_i-wx_i \nonumber\\&=\bar{y}-w\bar{x} \tag{1.6}\
\end{align}
$$

$$
\begin{align}
w\sum_{i=1}^m{x_i^2}=\sum_{i=1}^m{(y_i-b)x_i}\tag{1.7}
\end{align}
$$

将(1.6)带入(1.7)得到：

$$
\begin{align}
  w\sum_{i=1}^m{x_i^2}&=\sum_{i=1}^m{(y_ix_i)-\sum_{i=1}^m(\bar{y}-w\bar{x})x_i}\nonumber \\ &=\sum_{i=1}^my_ix_i - \bar{y}\sum_{i=1}^mx_i+w\bar{x}\sum_{i=1}^mx_i \tag{1.8}
\end{align}
$$

对(1.8)式进行化简，最终可得:

$$
\begin{align}
  w = \frac{\sum_{i=1}^my_ix_i-\bar{y}\sum_{i=1}^mx_i}{\sum_{i=1}^mx_i^2-\sum_{i=1}^m\bar{x}x_i} \tag{1.9}
\end{align}
$$

又由于$\bar{y}\sum_{i=1}^mx_i=\frac{1}{m}\sum_{i=1}^m{y_i}\cdot\sum_{i=1}^mx_i=\bar{x}\sum_{i=1}^my_i$和$\bar{x}\sum_{i=1}^my_i=\frac{1}{m}\sum_{i=1}^mx_i\sum_{i=1}^mx_i=\frac{1}{m}\Big(\sum_{i=1}^mx_i\Big)^2$将这两个式子带入(1.9)式进行进一步化简得到：

$$
\begin{align}
  w=\frac{\sum_{i=1}^my_i(x_i-\bar{x})}{\sum_{i=1}^mx_i^2-\Big(\sum_{i=1}^mx_i\Big)^2}\tag{1.20}
\end{align}
$$

### 1.2.2 一元情形的矩阵形式

由于 python 中累加形式只能使用`for`循环进行迭代，运行效率比较低，如果将(1.20)式转化为矩阵形式可以使用`numpy`等第三方库对其矩阵运算进行加速，公式推导如下：

$$
\begin{matrix}\bar{y}\sum_{i=1}^mx_i\bar{x}\sum_{i=1}^my_i=\sum_{i=1}^m\bar{y}x_i=\sum_{i=1}^m\bar{x}y_i \tag{1.21}=m\bar{x}\bar{y}=\sum_{i=1}^m\bar{x}\bar{y}
\end{matrix}
$$

$$
\begin{align}
  \sum_{i=1}^mx_i\bar{x}=\bar{x}\sum_{i=1}^mx_i=\bar{x}\cdot m\cdot \frac{1}{m}\sum_{i=1}^mx_i=m\bar{x}^2=\sum_{i=1}^m\bar{x}^2\tag{1.22}
\end{align}
$$

将式(1.21)和式(1.22)带入式(1.9)可以得到：

$$
\begin{align}
  w&=\frac{\sum_{i=1}^m(y_ix_i-y_i\bar{x}-x_i\bar{y}+\bar{x}\bar{y})}{\sum_{i=1}^m(x_i^2-\bar{x}x_i-\bar{x}x_i+\bar{x}^2)} \nonumber\\&=\frac{\sum_{i=1}^m(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^m(x_i-\bar{x})^2} \tag{1.23}
\end{align}
$$

记$x=(x_1;x_2...x_m)$,$x_d=(x_i-\bar{x};x_2-\bar{x}...x_m-\bar{x})$,$y_d$同$x_d$,再由向量内积的定义可以得到:

$$
\begin{align}
  w=\frac{x_d^Ty_d}{x_d^Tx_d}\tag{1.24}
\end{align}
$$

### 1.2.3 多元
多元的情形可由一元的情形举一反三推导出，如下：
$$
\begin{align}
w^*&=\mathop{\arg\min}\limits_{(\hat{w})}\sum_{i=1}^{m}{(y_i-\hat{w}^Tx_i)^2} \nonumber\\ &=\mathop{\arg\min}\limits_{(\hat{w})}\sum_{i=1}^{m}{(y_i-x_i^T\hat{w})^2} \nonumber \\ &=\mathop{\arg\min}\limits_{(\hat{w})}\begin{bmatrix}y_1-x_1^T\hat{w}\dots y_m-x_m^T\hat{w}\end{bmatrix} \cdot \begin{bmatrix}y_1-x_1^T\hat{w} \\ \dots \\ y_m-x_m^T\hat{w}\end{bmatrix} \tag{1.25}
\end{align}
$$

其中：
$$
\begin{align}\begin{bmatrix}y_1-x_1^T\hat{w} \\ y_2-x_2^T\hat{w} \\\dots \\ y_m-x_m^T\hat{w}\end{bmatrix}&=\begin{bmatrix}y_1\\ y_2\\ \dots\\ y_m\end{bmatrix} - \begin{bmatrix}x_1^T\hat{w}\\ x_2^T\hat{w} \\ \dots\\ x_m^T\hat{w}\end{bmatrix} \nonumber \\ &=y-\begin{bmatrix}x_1^T \\ x_2^T \\ \dots \\ x_m^T\end{bmatrix}\cdot \hat{w} \nonumber \\ &= y-X\hat{w} \tag{1.26}\end{align}
$$
所以:
$$
\begin{align}\hat{w}^*=\mathop{\arg\min}\limits_{(\hat{w})}(y-X\hat{w})^T(y-X\hat{w}) \tag{1.27}\end{align}
$$
现引入两个定理对$\hat{w}$的最优解做进一步推导。

### 1.2.4 $\hat{w}的求解$
$Def_{1.28}$：设$D\subset R^n$为非空开凸集$f(x)$是定义在$D$上的实值函数，且$f(x)$在$D$上二阶连续可微，若$f(x)$的$Hession$矩阵$\nabla^2f(x)$在$D$上半正定则$f(x)$是$D$上的凸函数，若$\nabla^2f(x$)在$D$上正定则$f(x)$为$D$上的严格凸函数。

$Def_{1.29}$：若$f(x)$为凸函数且$f(x)$一阶连续可微则$x^*$是全局最优解的充要条件为其梯度等于零向量即:$$\nabla f(x^*)=\textbf{0}\tag{1.30}$$
为了书写方便，我们现在令$E_{\hat{w}}=(y-X\hat{w})^T(y-X\hat{w})$,展开然后等式两端对$\hat{w}$求导有：
$$
\begin{align}E_{\hat{w}}&=(y-X\hat{w})^T(y-X\hat{w})\nonumber \\&= y^Ty-y^TX\hat{w}-\hat{w}^TX^Ty+\hat{w}^TX^TX\hat{w}\tag{1.31} \end{align}
$$

$$
\begin{align}\frac{\partial E\hat{w}}{\partial \hat{w}}&= 0-X^Ty-X^Ty+(X^TX+X^TX)\hat{w}\nonumber\\&=2X^T(X\hat{w}-y)\tag{1.32}\end{align}
$$


由式(1.32)再对$\hat{w}^T$求偏导可以得到$E_{\hat{w}} Hession$矩阵的表达式，如下：
$$
\begin{align}\nabla^2 E_{\hat{w}}&=\frac{\partial }{\partial w^T}\Big (\frac{\partial E\hat{w}}{\partial w}\Big) \nonumber \\ &=2X^TX \tag{1.33}\end{align}
$$
由$Def_{1.28},Def_{1.29}$当$X^TX$为正定矩阵时，令其梯度为零向量可解得方程的全局最优解即：
$$
\begin{align}\hat{w}^*=(X^TX)^{-1}X^Ty \tag{1.34}\end{align}
$$


